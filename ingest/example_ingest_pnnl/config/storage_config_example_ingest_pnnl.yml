storage:
  # This section should not be modified unless there is a strong need. It is set up to
  # use environment variables to set the settings. These variables are automatically set
  # by the various entry points to this ingest and should not be modified unless you
  # know what you are doing.
  classname: ${STORAGE_CLASSNAME}
  parameters:
    retain_input_files: ${RETAIN_INPUT_FILES}
    root_dir: ${ROOT_DIR}
    bucket_name: ${STORAGE_BUCKET}

  file_handlers:
    # FileHandlers are split into two categories: those used for reading input, and
    # those meant for writing output files. Each FileHandler configuration block
    # consists of the following components:
    #
    # 1) label (e.g. 'netcdf') - solely used for orgnaization within this config file
    # 2) file_pattern - a regex string (or list of strings) for which the FileHandler
    # should be used. Only applicable for input FileHandlers.
    # 3) file_extension - the file extension. Used in output FileHandlers, but also
    # can be used in place of a file_pattern for input FileHandlers.
    # 4) classname - tells which FileHandler should be used
    # 5) parameters - additonal parameters that will be passed to the FileHandler for it
    # to use as it sees fit.

    input:
      csv:
        # Here we define single FileHandler for reading input data. The FileHandler is
        # configured to run for files ending in '.csv' and uses the built-in
        # CsvHandler from the tsdat.io.filehandlers module with some specific parameters
        # that help us read data from our example csv file.
        file_pattern: '.*\.csv'
        classname: tsdat.io.filehandlers.CsvHandler
        parameters:
          read:
            # You can add parameters that are passed to pandas.read_csv() as keyword
            # arguments. See the pandas.read_csv() docs for more details.
            read_csv:
              index_col: False # Treat the first column (time) as a data variable
              header: 2 # Where to look for the header (header = line number - 1)

    # We highly recommend writing to the netcdf format whenever possible, as this format
    # preserves the data structure and metadata as configured in the pipeline config
    # file, however we recognize that sometimes this is not possible. Our recommendation
    # in these situations is to just be aware that many formats (such as csv) do not
    # support embedding metadata into your output files, so you should careful consider
    # how metadata is captured and reported so as to avoid data loss.
    output:
      netcdf:
        file_extension: ".nc"
        classname: tsdat.io.filehandlers.NetCdfHandler
