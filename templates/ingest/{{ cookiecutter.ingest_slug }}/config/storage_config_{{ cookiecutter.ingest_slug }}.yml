{% if cookiecutter.add_help == "yes" %}storage:
  # This section should not be modified unless there is a strong need. It is set up to
  # use environment variables to set the settings. These variables are automatically set
  # by the various entry points to this ingest and should not be modified unless you
  # know what you are doing.
  classname: ${STORAGE_CLASSNAME}
  parameters:
    retain_input_files: ${RETAIN_INPUT_FILES}
    root_dir: ${ROOT_DIR}
    bucket_name: ${STORAGE_BUCKET}

  # TODO – Developer: Update the file_handlers as needed
  file_handlers:
    # FileHandlers are split into two categories: those used for reading input, and
    # those meant for writing output files. Each FileHandler configuration block
    # consists of the following components:
    #
    # 1) label (e.g. 'netcdf') - solely used for orgnaization within this config file
    # 2) file_pattern - a regex string (or list of strings) for which the FileHandler
    # should be used. Only applicable for input FileHandlers.
    # 3) file_extension - the file extension. Used in output FileHandlers, but also
    # can be used in place of a file_pattern for input FileHandlers.
    # 4) classname - tells which FileHandler should be used
    # 5) parameters - additonal parameters that will be passed to the FileHandler for it
    # to use as it sees fit.

    input: {% if cookiecutter.use_custom_filehandler == "yes" %}
      my_custom_format:
        # This is where you define/configure your custom FileHandler for use in your
        # pipeline. At a minimum, you should update the file_pattern and classname
        # options so that they match your data and python class name, respectively. We
        # also recommend adding parameters if possible so that your code is more
        # modular and reusable. See the csv configuration below as well as the tsdat
        # CsvHandler implementation for more information as needed.
        file_pattern: '.*\.custom_extension'
        classname: ingest.{{ cookiecutter.ingest_slug }}.pipeline.filehandler.CustomFileHandler
        # parameters:
        #   # If you choose, you can define parameters here that will be available for
        #   # you to use in your custom FileHandler. This is entirely optional, but we
        #   # highly recommend making good use of it.
        #   read:
        #     some_custom_option: True

      # csv:
      #   # Here we define single FileHandler for reading input data. The FileHandler is
      #   # configured to run for files ending in '.csv' and uses the built-in
      #   # CsvHandler from the tsdat.io.filehandlers module with some specific parameters
      #   # that help us read data from our example csv file.
      #   file_pattern: '.*\.csv'
      #   classname: tsdat.io.filehandlers.CsvHandler
      #   parameters:
      #     read:
      #       # You can add parameters that are passed to pandas.read_csv() as keyword
      #       # arguments. See the pandas.read_csv() docs for more details.
      #       read_csv:
      #         index_col: False # Treat the first column (time) as a data variable
      #         header: 2 # Where to look for the header (header = line number - 1){% else %}
      csv:
        # Here we define single FileHandler for reading input data. The FileHandler is
        # configured to run for files ending in '.csv' and uses the built-in
        # CsvHandler from the tsdat.io.filehandlers module with some specific parameters
        # that help us read data from our example csv file.
        file_pattern: '.*\.csv'
        classname: tsdat.io.filehandlers.CsvHandler
        parameters:
          read:
            # You can add parameters that are passed to pandas.read_csv() as keyword
            # arguments. See the pandas.read_csv() docs for more details.
            read_csv:
              index_col: False # Treat the first column (time) as a data variable
              header: 2 # Where to look for the header (header = line number - 1){% endif %}   

    output:
      # We highly recommend writing to the netcdf format whenever possible, as this format
      # preserves the data structure and metadata as configured in the pipeline config
      # file, however we recognize that sometimes this is not possible. Our recommendation
      # in these situations is to just be aware that many formats (such as csv) do not
      # support embedding metadata into your output files, so you should careful consider
      # how metadata is captured and reported so as to avoid data loss.
      
      netcdf:
        file_extension: ".nc"
        classname: tsdat.io.filehandlers.NetCdfHandler
{% else %}storage:
  # This section should not be modified unless there is a strong need. It is set up to
  # use environment variables to set the settings. These variables are automatically set
  # by the various entry points to this ingest and should not be modified unless you
  # know what you are doing.
  classname: ${STORAGE_CLASSNAME}
  parameters:
    retain_input_files: ${RETAIN_INPUT_FILES}
    root_dir: ${ROOT_DIR}
    bucket_name: ${STORAGE_BUCKET}

  # TODO – Developer: Update the file_handlers as needed
  file_handlers:
    input: {% if cookiecutter.use_custom_filehandler == "yes" %}
      my_custom_format:
        file_pattern: '.*\.custom_extension'
        classname: ingest.{{ cookiecutter.ingest_slug }}.pipeline.filehandler.CustomFileHandler{% else %}

      csv:
        file_pattern: '.*\.csv'
        classname: tsdat.io.filehandlers.CsvHandler
        parameters:
          read:
            read_csv:
              index_col: False
              header: 2{% endif %}

    output:
      netcdf:
        file_extension: ".nc"
        classname: tsdat.io.filehandlers.NetCdfHandler
{% endif %}